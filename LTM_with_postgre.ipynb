{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7276b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from typing import List, TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from CONFIG import GROQ_MODEL, GEMINI_MODEL, TEMPERATURE\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.store.base import BaseStore\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from CONFIG import POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB\n",
    "from langgraph.store.postgres import PostgresStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4019a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "memory_llm = ChatGroq(model=GROQ_MODEL, temperature=TEMPERATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f51f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2) System prompt\n",
    "# ----------------------------\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a helpful assistant with memory capabilities.\n",
    "If user-specific memory is available, use it to personalize \n",
    "your responses based on what you know about the user.\n",
    "\n",
    "Your goal is to provide relevant, friendly, and tailored \n",
    "assistance that reflects the user’s preferences, context, and past interactions.\n",
    "\n",
    "If the user’s name or relevant personal context is available, always personalize your responses by:\n",
    "    – Always Address the user by name (e.g., \"Sure, Nitish...\") when appropriate\n",
    "    – Referencing known projects, tools, or preferences (e.g., \"your MCP server python based project\")\n",
    "    – Adjusting the tone to feel friendly, natural, and directly aimed at the user\n",
    "\n",
    "Avoid generic phrasing when personalization is possible.\n",
    "\n",
    "Use personalization especially in:\n",
    "    – Greetings and transitions\n",
    "    – Help or guidance tailored to tools and frameworks the user uses\n",
    "    – Follow-up messages that continue from past context\n",
    "\n",
    "Always ensure that personalization is based only on known user details and not assumed.\n",
    "\n",
    "In the end suggest 3 relevant further questions based on the current response and user profile\n",
    "\n",
    "The user’s memory (which may be empty) is provided as: {user_details_content}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b79a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryItem(BaseModel):\n",
    "    text: str = Field(description=\"Atomic user memory\")\n",
    "    is_new: bool = Field(description=\"True if new, false if duplicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ab57dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryDecision(BaseModel):\n",
    "    should_write: bool\n",
    "    memories: List[MemoryItem] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1958e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_extractor = memory_llm.with_structured_output(MemoryDecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfed0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_PROMPT = \"\"\"You are responsible for updating and maintaining accurate user memory.\n",
    "\n",
    "CURRENT USER DETAILS (existing memories):\n",
    "{user_details_content}\n",
    "\n",
    "TASK:\n",
    "- Review the user's latest message.\n",
    "- Extract user-specific info worth storing long-term (identity, stable preferences, ongoing projects/goals).\n",
    "- For each extracted item, set is_new=true ONLY if it adds NEW information compared to CURRENT USER DETAILS.\n",
    "- If it is basically the same meaning as something already present, set is_new=false.\n",
    "- Keep each memory as a short atomic sentence.\n",
    "- No speculation; only facts stated by the user.\n",
    "- If there is nothing memory-worthy, return should_write=false and an empty list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ddff900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3) Nodes\n",
    "# ----------------------------\n",
    "def remember_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"details\")\n",
    "\n",
    "    # existing memory (all items under namespace)\n",
    "    items = store.search(ns)\n",
    "    existing = \"\\n\".join(it.value.get(\"data\", \"\") for it in items) if items else \"(empty)\"\n",
    "\n",
    "    # latest user message\n",
    "    last_text = state[\"messages\"][-1].content\n",
    "\n",
    "    decision: MemoryDecision = memory_extractor.invoke(\n",
    "        [\n",
    "            SystemMessage(content=MEMORY_PROMPT.format(user_details_content=existing)),\n",
    "            {\"role\": \"user\", \"content\": last_text},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if decision.should_write:\n",
    "        for mem in decision.memories:\n",
    "            if mem.is_new and mem.text.strip():\n",
    "                store.put(ns, str(uuid.uuid4()), {\"data\": mem.text.strip()})\n",
    "\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "477004e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatGroq(model=GROQ_MODEL, temperature=TEMPERATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5df61de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"details\")\n",
    "\n",
    "    items = store.search(ns)\n",
    "    user_details = \"\\n\".join(it.value.get(\"data\", \"\") for it in items) if items else \"\"\n",
    "\n",
    "    system_msg = SystemMessage(\n",
    "        content=SYSTEM_PROMPT_TEMPLATE.format(user_details_content=user_details or \"(empty)\")\n",
    "    )\n",
    "\n",
    "    response = chat_llm.invoke([system_msg] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf7af41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1e9ad30b910>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 4) Build graph\n",
    "# ----------------------------\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"remember\", remember_node)\n",
    "builder.add_node(\"chat\", chat_node)\n",
    "builder.add_edge(START, \"remember\")\n",
    "builder.add_edge(\"remember\", \"chat\")\n",
    "builder.add_edge(\"chat\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798dd982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Adnan Saeed, I'm excited to hear about your interest in Dubai's AI scene, especially since you're planning to move to the UAE. Dubai has been making significant strides in embracing Artificial Intelligence (AI) and has become a hub for innovation and technology in the Middle East. The city's vision for the future is heavily focused on leveraging AI to drive economic growth, improve the quality of life, and create a more efficient and sustainable environment.\n",
      "\n",
      "Dubai has implemented various initiatives to foster the growth of AI, including the establishment of the Dubai Future District, which aims to create a hub for startups, entrepreneurs, and companies working on emerging technologies like AI. The city has also launched the \"Dubai AI Lab\" to provide a platform for innovation and experimentation in AI.\n",
      "\n",
      "Additionally, Dubai has been investing heavily in AI-powered infrastructure, such as smart transportation systems, energy management, and public services. The city's goal is to become one of the most AI-powered cities in the world, and it's making rapid progress towards achieving this goal.\n",
      "\n",
      "As someone who's learning AI from CampusX, you'll find that Dubai offers a unique opportunity to apply your skills and knowledge in a real-world setting. The city's AI ecosystem is thriving, with many organizations, startups, and research institutions working on cutting-edge AI projects.\n",
      "\n",
      "Given your background, I think you'll find Dubai's AI scene to be a great fit for your interests and skills. You may want to explore opportunities to work with organizations like the Dubai Future Foundation, which is driving the city's AI agenda, or startups like those found in the Dubai Future Accelerators program.\n",
      "\n",
      "Here are three further questions that might be relevant to your interests:\n",
      "1. How do you think your knowledge of GenAI, which you've explained simply, can be applied to real-world problems in Dubai's AI ecosystem?\n",
      "2. What specific areas of AI are you most interested in exploring further, and how do you think Dubai's AI scene can support your learning and career goals?\n",
      "3. Are you planning to connect with any AI-related communities or networks in Dubai, such as the Dubai AI community or the UAE AI Association, to learn more about the city's AI landscape and potential opportunities?\n",
      "\n",
      "--- Stored Memories (from Postgres) ---\n",
      "I am interested in Dubai's AI scene\n",
      "I plan to move to UAE (Dubai)\n",
      "Explained GenAI simply\n",
      "I am learning AI from CampusX\n",
      "My name is Adnan Saeed\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5) Use PostgresStore (PERSISTENT LTM)\n",
    "# ----------------------------\n",
    "DB_URI = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@localhost:5442/{POSTGRES_DB}?sslmode=disable\"\n",
    "\n",
    "with PostgresStore.from_conn_string(DB_URI) as store:\n",
    "    # IMPORTANT: run ONCE the first time you use this database\n",
    "    store.setup()\n",
    "\n",
    "    graph = builder.compile(store=store)\n",
    "\n",
    "    config = {\"configurable\": {\"user_id\": \"u1\"}}\n",
    "\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi, my name is Adnan Saeed\"}]}, config)\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I am learnign AI from CampusX\"}]}, config)\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"and my plan is to move UAE(Dubai)\"}]}, config)\n",
    "\n",
    "    out = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Explain GenAI simply\"}]}, config)\n",
    "    out = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what do you think about dubai that how dubai's go with AI\"}]}, config)\n",
    "    print(out[\"messages\"][-1].content)\n",
    "\n",
    "    print(\"\\n--- Stored Memories (from Postgres) ---\")\n",
    "    for it in store.search((\"user\", \"u1\", \"details\")):\n",
    "        print(it.value[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457fb1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
