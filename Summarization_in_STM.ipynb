{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd7bc528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_core.messages import HumanMessage, BaseMessage, SystemMessage, RemoveMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from CONFIG import GROQ_MODEL, TEMPERATURE\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f23c6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatGroq(model=GROQ_MODEL, temperature=TEMPERATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "71174504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class state_graph(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7cb107bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: state_graph):\n",
    "    messages = []\n",
    "\n",
    "    if state['summary']:\n",
    "        messages.append(\n",
    "            SystemMessage(content=f\"conversation summary:\\n {state['summary']}\")\n",
    "        )\n",
    "    messages.extend(state['messages'])\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ab38c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization_node(state: state_graph):\n",
    "    existing_summary = state['summary']\n",
    "\n",
    "    if existing_summary:\n",
    "        prompt = (\n",
    "            f\"\"\"\n",
    "        Existing summary is \\n {existing_summary} \\n\n",
    "        Extand the summary using the new conversation above\"\"\"\n",
    "      )\n",
    "        \n",
    "    else:\n",
    "        prompt = \"Generate the summary of above conversation\"\n",
    "        \n",
    "    messages_for_sumamry = state['messages'] + [HumanMessage(content=prompt)]\n",
    "    response = llm.invoke(messages_for_sumamry)\n",
    "\n",
    "    messages_for_delete = state['messages'][:-2]\n",
    "    return {\n",
    "        'summary': response.content,\n",
    "        'messages': [RemoveMessage(id=m.id) for m in messages_for_delete]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6483bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_summarize(state: state_graph):\n",
    "    return len(state['messages']) > 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fb853a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x28150a6ebd0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(state_graph)\n",
    "\n",
    "builder.add_node('chat_node', chat_node)\n",
    "builder.add_node('summarization_node', summarization_node)\n",
    "\n",
    "builder.add_edge(START, 'chat_node')\n",
    "builder.add_conditional_edges(\n",
    "    'chat_node',\n",
    "    should_summarize,\n",
    "    {\n",
    "        True: 'summarization_node',\n",
    "        False: END\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge('summarization_node', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "906712ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1af6a059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Question: agentic ai just inshort\n",
      "AI Response: Agentic AI refers to artificial intelligence systems that can act independently, making decisions and taking actions based on their own goals and motivations, rather than just following pre-programmed instructions.\n"
     ]
    }
   ],
   "source": [
    "config = {'configurable': {'thread_id': 'thread-1'}}\n",
    "output = graph.invoke({'messages': [HumanMessage(content=\"agentic ai just inshort\")], 'summary':''}, config=config)\n",
    "print(f\"Human Question: {output['messages'][0].content}\")\n",
    "print(f\"AI Response: {output['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e410aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Question: agentic ai just inshort\n",
      "AI Response: n8n is a workflow automation tool that offers several benefits, including:\n",
      "\n",
      "1. **Low-code automation**: n8n allows users to automate workflows without extensive coding knowledge.\n",
      "2. **Customizable**: Highly customizable, enabling users to create tailored workflows for specific needs.\n",
      "3. **Integration with various services**: Supports integration with multiple services, such as APIs, databases, and messaging platforms.\n",
      "4. **Flexible workflow design**: Enables users to design complex workflows using a visual interface.\n",
      "5. **Error handling and debugging**: Provides features for error handling and debugging, making it easier to troubleshoot workflows.\n",
      "6. **Scalability**: Designed to handle large volumes of data and scale with growing needs.\n",
      "7. **Open-source**: n8n is open-source, which means it's free to use and modify.\n",
      "8. **Community support**: Has an active community of users and developers who contribute to its growth and provide support.\n",
      "\n",
      "Overall, n8n helps streamline workflows, increase productivity, and reduce manual effort by automating repetitive tasks.\n"
     ]
    }
   ],
   "source": [
    "config = {'configurable': {'thread_id': 'thread-1'}}\n",
    "output = graph.invoke({'messages': [HumanMessage(content=\"any banifit of n8n\")], 'summary':''}, config=config)\n",
    "print(f\"Human Question: {output['messages'][0].content}\")\n",
    "print(f\"AI Response: {output['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6ec3ac3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='agentic ai just inshort', additional_kwargs={}, response_metadata={}, id='ce0b1efc-5370-4c28-89dd-596a406b92b8'),\n",
       " AIMessage(content='Agentic AI refers to artificial intelligence systems that can act independently, making decisions and taking actions based on their own goals and motivations, rather than just following pre-programmed instructions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 41, 'total_tokens': 77, 'completion_time': 0.102995779, 'completion_tokens_details': None, 'prompt_time': 0.001947081, 'prompt_tokens_details': None, 'queue_time': 0.008472987, 'total_time': 0.10494286}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb855-4b97-78f1-9d92-e26ffb312f61-0', usage_metadata={'input_tokens': 41, 'output_tokens': 36, 'total_tokens': 77}),\n",
       " HumanMessage(content='any banifit of n8n', additional_kwargs={}, response_metadata={}, id='84fb9117-12e8-4055-9464-a60bd8d293ce'),\n",
       " AIMessage(content=\"n8n is a workflow automation tool that offers several benefits, including:\\n\\n1. **Low-code automation**: n8n allows users to automate workflows without extensive coding knowledge.\\n2. **Customizable**: Highly customizable, enabling users to create tailored workflows for specific needs.\\n3. **Integration with various services**: Supports integration with multiple services, such as APIs, databases, and messaging platforms.\\n4. **Flexible workflow design**: Enables users to design complex workflows using a visual interface.\\n5. **Error handling and debugging**: Provides features for error handling and debugging, making it easier to troubleshoot workflows.\\n6. **Scalability**: Designed to handle large volumes of data and scale with growing needs.\\n7. **Open-source**: n8n is open-source, which means it's free to use and modify.\\n8. **Community support**: Has an active community of users and developers who contribute to its growth and provide support.\\n\\nOverall, n8n helps streamline workflows, increase productivity, and reduce manual effort by automating repetitive tasks.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 209, 'prompt_tokens': 94, 'total_tokens': 303, 'completion_time': 0.686643271, 'completion_tokens_details': None, 'prompt_time': 0.007619131, 'prompt_tokens_details': None, 'queue_time': 0.008360627, 'total_time': 0.694262402}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb855-4d7a-73c2-9198-c976f36083b6-0', usage_metadata={'input_tokens': 94, 'output_tokens': 209, 'total_tokens': 303})]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = graph.get_state(config).values['messages']\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fead8428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='agentic ai just inshort', additional_kwargs={}, response_metadata={}, id='ce0b1efc-5370-4c28-89dd-596a406b92b8'), AIMessage(content='Agentic AI refers to artificial intelligence systems that can act independently, making decisions and taking actions based on their own goals and motivations, rather than just following pre-programmed instructions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 41, 'total_tokens': 77, 'completion_time': 0.102995779, 'completion_tokens_details': None, 'prompt_time': 0.001947081, 'prompt_tokens_details': None, 'queue_time': 0.008472987, 'total_time': 0.10494286}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb855-4b97-78f1-9d92-e26ffb312f61-0', usage_metadata={'input_tokens': 41, 'output_tokens': 36, 'total_tokens': 77}), HumanMessage(content='any banifit of n8n', additional_kwargs={}, response_metadata={}, id='84fb9117-12e8-4055-9464-a60bd8d293ce'), AIMessage(content=\"n8n is a workflow automation tool that offers several benefits, including:\\n\\n1. **Low-code automation**: n8n allows users to automate workflows without extensive coding knowledge.\\n2. **Customizable**: Highly customizable, enabling users to create tailored workflows for specific needs.\\n3. **Integration with various services**: Supports integration with multiple services, such as APIs, databases, and messaging platforms.\\n4. **Flexible workflow design**: Enables users to design complex workflows using a visual interface.\\n5. **Error handling and debugging**: Provides features for error handling and debugging, making it easier to troubleshoot workflows.\\n6. **Scalability**: Designed to handle large volumes of data and scale with growing needs.\\n7. **Open-source**: n8n is open-source, which means it's free to use and modify.\\n8. **Community support**: Has an active community of users and developers who contribute to its growth and provide support.\\n\\nOverall, n8n helps streamline workflows, increase productivity, and reduce manual effort by automating repetitive tasks.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 209, 'prompt_tokens': 94, 'total_tokens': 303, 'completion_time': 0.686643271, 'completion_tokens_details': None, 'prompt_time': 0.007619131, 'prompt_tokens_details': None, 'queue_time': 0.008360627, 'total_time': 0.694262402}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb855-4d7a-73c2-9198-c976f36083b6-0', usage_metadata={'input_tokens': 94, 'output_tokens': 209, 'total_tokens': 303})], 'summary': ''}, next=(), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f0a29-81c9-60c2-8004-5787ad3047ca'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2026-01-13T17:09:17.586246+00:00', parent_config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f0a29-7a36-607c-8003-5b8a4f110c01'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824eee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72080b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
