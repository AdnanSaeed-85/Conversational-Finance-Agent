{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97fb9a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_groq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m START, END, StateGraph\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add_messages\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\langchain_groq\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Groq integration for LangChain.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_groq\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_groq\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m      6\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mChatGroq\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__version__\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:15\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Literal, cast\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     AsyncCallbackManagerForLLMRun,\n\u001b[32m     13\u001b[39m     CallbackManagerForLLMRun,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     LanguageModelInput,\n\u001b[32m     17\u001b[39m     ModelProfile,\n\u001b[32m     18\u001b[39m     ModelProfileRegistry,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     BaseChatModel,\n\u001b[32m     22\u001b[39m     LangSmithParams,\n\u001b[32m     23\u001b[39m     agenerate_from_stream,\n\u001b[32m     24\u001b[39m     generate_from_stream,\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     27\u001b[39m     AIMessage,\n\u001b[32m     28\u001b[39m     AIMessageChunk,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     ToolMessageChunk,\n\u001b[32m     43\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1229\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\__init__.py:110\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(attr_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    109\u001b[39m     module_name = _dynamic_imports.get(attr_name)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     result = \u001b[43mimport_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__spec__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[attr_name] = result\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\langchain_core\\_import_utils.py:35\u001b[39m, in \u001b[36mimport_attr\u001b[39m\u001b[34m(attr_name, module_name, package)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         module = \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     37\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\base.py:41\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMResult\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT2TokenizerFast  \u001b[38;5;66;03m# type: ignore[import-not-found]\u001b[39;00m\n\u001b[32m     43\u001b[39m     _HAS_TRANSFORMERS = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\transformers\\__init__.py:958\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m    956\u001b[39m _import_structure = {k: \u001b[38;5;28mset\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _import_structure.items()}\n\u001b[32m--> \u001b[39m\u001b[32m958\u001b[39m import_structure = \u001b[43mdefine_import_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[34;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    959\u001b[39m import_structure[\u001b[38;5;28mfrozenset\u001b[39m({})].update(_import_structure)\n\u001b[32m    961\u001b[39m sys.modules[\u001b[34m__name__\u001b[39m] = _LazyModule(\n\u001b[32m    962\u001b[39m     \u001b[34m__name__\u001b[39m,\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[33m\"\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    966\u001b[39m     extra_objects={\u001b[33m\"\u001b[39m\u001b[33m__version__\u001b[39m\u001b[33m\"\u001b[39m: __version__},\n\u001b[32m    967\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2867\u001b[39m, in \u001b[36mdefine_import_structure\u001b[39m\u001b[34m(module_path, prefix)\u001b[39m\n\u001b[32m   2843\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[32m   2844\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefine_import_structure\u001b[39m(module_path: \u001b[38;5;28mstr\u001b[39m, prefix: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> IMPORT_STRUCTURE_T:\n\u001b[32m   2845\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2846\u001b[39m \u001b[33;03m    This method takes a module_path as input and creates an import structure digestible by a _LazyModule.\u001b[39;00m\n\u001b[32m   2847\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2865\u001b[39m \u001b[33;03m    If `prefix` is not None, it will add that prefix to all keys in the returned dict.\u001b[39;00m\n\u001b[32m   2866\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2867\u001b[39m     import_structure = \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2868\u001b[39m     spread_dict = spread_import_structure(import_structure)\n\u001b[32m   2870\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2580\u001b[39m, in \u001b[36mcreate_import_structure_from_path\u001b[39m\u001b[34m(module_path)\u001b[39m\n\u001b[32m   2578\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(module_path):\n\u001b[32m   2579\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m f != \u001b[33m\"\u001b[39m\u001b[33m__pycache__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m os.path.isdir(os.path.join(module_path, f)):\n\u001b[32m-> \u001b[39m\u001b[32m2580\u001b[39m         import_structure[f] = \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2582\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(os.path.join(directory, f)):\n\u001b[32m   2583\u001b[39m         adjacent_modules.append(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2604\u001b[39m, in \u001b[36mcreate_import_structure_from_path\u001b[39m\u001b[34m(module_path)\u001b[39m\n\u001b[32m   2601\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_name.endswith(\u001b[33m\"\u001b[39m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   2602\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2604\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(directory, module_name), encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   2605\u001b[39m     file_content = f.read()\n\u001b[32m   2607\u001b[39m \u001b[38;5;66;03m# Remove the .py suffix\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:309\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, errors)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated, TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages.utils import trim_messages, count_tokens_approximately\n",
    "from CONFIG import GROQ_MODEL, TEMPERATURE, MAX_TOKENS, GEMINI_MODEL\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# llm = ChatGroq(model=GROQ_MODEL, temperature=TEMPERATURE)\n",
    "llm = ChatGoogleGenerativeAI(model=GEMINI_MODEL, temperature=TEMPERATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24330d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class state_graph(TypedDict):\n",
    "    message: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915325d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: state_graph):\n",
    "    message = trim_messages(\n",
    "        state['message'],\n",
    "        strategy='last',\n",
    "        token_counter=count_tokens_approximately,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "    )\n",
    "\n",
    "    print('Current Token Count -> ', count_tokens_approximately(messages=message))\n",
    "\n",
    "    for msg in message:\n",
    "        print(msg.content)\n",
    "        \n",
    "    response = llm.invoke(message)\n",
    "    return {'message': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779296de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1eabeb87290>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(state_graph)\n",
    "builder.add_node('chat_node', chat_node)\n",
    "builder.add_edge(START, 'chat_node')\n",
    "builder.add_edge('chat_node', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be22556",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Install Pyppeteer to use the Pyppeteer method: `pip install pyppeteer`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MermaidDrawMethod\n\u001b[32m      7\u001b[39m graph = builder.compile()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMermaidDrawMethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPYPPETEER\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:693\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config, base_url, proxies)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: PLC0415\u001b[39;00m\n\u001b[32m    684\u001b[39m     draw_mermaid_png,\n\u001b[32m    685\u001b[39m )\n\u001b[32m    687\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    688\u001b[39m     curve_style=curve_style,\n\u001b[32m    689\u001b[39m     node_colors=node_colors,\n\u001b[32m    690\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    691\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    692\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:307\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, base_url, proxies)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Draws a Mermaid graph as PNG using provided syntax.\u001b[39;00m\n\u001b[32m    288\u001b[39m \n\u001b[32m    289\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    304\u001b[39m \u001b[33;03m    ValueError: If an invalid draw method is provided.\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m draw_method == MermaidDrawMethod.PYPPETEER:\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     img_bytes = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_render_mermaid_using_pyppeteer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m    313\u001b[39m     img_bytes = _render_mermaid_using_api(\n\u001b[32m    314\u001b[39m         mermaid_syntax,\n\u001b[32m    315\u001b[39m         output_file_path=output_file_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m         proxies=proxies,\n\u001b[32m    321\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\AI_Projects\\AI Conversational Agent\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:343\u001b[39m, in \u001b[36m_render_mermaid_using_pyppeteer\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, padding, device_scale_factor)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _HAS_PYPPETEER:\n\u001b[32m    342\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInstall Pyppeteer to use the Pyppeteer method: `pip install pyppeteer`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    345\u001b[39m browser = \u001b[38;5;28;01mawait\u001b[39;00m launch()\n\u001b[32m    346\u001b[39m page = \u001b[38;5;28;01mawait\u001b[39;00m browser.newPage()\n",
      "\u001b[31mImportError\u001b[39m: Install Pyppeteer to use the Pyppeteer method: `pip install pyppeteer`."
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Now your existing code should work:\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "graph = builder.compile()\n",
    "graph.get_graph().draw_mermaid_png(\n",
    "    draw_method=MermaidDrawMethod.PYPPETEER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a501a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-conversational-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
