{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fb9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated, TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages.utils import trim_messages, count_tokens_approximately\n",
    "from CONFIG import GROQ_MODEL, TEMPERATURE, MAX_TOKENS, GEMINI_MODEL\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "740a257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatGroq(model=GROQ_MODEL, temperature=TEMPERATURE)\n",
    "# llm = ChatGoogleGenerativeAI(model=GEMINI_MODEL, temperature=TEMPERATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24330d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class state_graph(TypedDict):\n",
    "    message: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "915325d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: state_graph):\n",
    "    message = trim_messages(\n",
    "        state['message'],\n",
    "        strategy='last',\n",
    "        token_counter=count_tokens_approximately,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "    )\n",
    "\n",
    "    print('Current Token Count -> ', count_tokens_approximately(messages=message))\n",
    "\n",
    "    for msg in message:\n",
    "        print(msg.content)\n",
    "        \n",
    "    response = llm.invoke(message)\n",
    "    return {'message': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "779296de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1dac5efee50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(state_graph)\n",
    "builder.add_node('chat_node', chat_node)\n",
    "builder.add_edge(START, 'chat_node')\n",
    "builder.add_edge('chat_node', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7a501a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6383de04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count ->  8\n",
      "hi how are you?\n",
      "Hello. I'm just a computer program, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "config = {'configurable': {'thread_id': '91'}}\n",
    "out1 = graph.invoke({'message': HumanMessage(content='hi how are you?')}, config)\n",
    "out1 = out1['message'][-1].content\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8821f2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count ->  66\n",
      "hi how are you?\n",
      "Hello. I'm just a computer program, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to assist you. How can I help you today?\n",
      "do you know about me?\n",
      "I don't have any personal information about you. I'm a large language model, I don't have the ability to store or access information about individual users. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations.\n",
      "\n",
      "However, as we chat, I can learn more about your interests and preferences based on what you share with me. If you'd like to tell me a bit about yourself, I'm here to listen and help with any questions or topics you'd like to discuss. What's on your mind?\n"
     ]
    }
   ],
   "source": [
    "out1 = graph.invoke({'message': HumanMessage(content='do you know about me?')}, config)\n",
    "out1 = out1['message'][-1].content\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b37faf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count ->  149\n",
      "I don't have any personal information about you. I'm a large language model, I don't have the ability to store or access information about individual users. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations.\n",
      "\n",
      "However, as we chat, I can learn more about your interests and preferences based on what you share with me. If you'd like to tell me a bit about yourself, I'm here to listen and help with any questions or topics you'd like to discuss. What's on your mind?\n",
      "ok my self adnan saeed\n",
      "Nice to meet you, Adnan Saeed! It's great to have you here. I hope you're doing well. Is there something specific you'd like to talk about or ask me, or would you like to just chat and see where the conversation goes?\n",
      "\n",
      "By the way, where are you from, Adnan? I'm curious to know more about you and your interests.\n"
     ]
    }
   ],
   "source": [
    "out1 = graph.invoke({'message': HumanMessage(content='ok my self adnan saeed')}, config)\n",
    "out1 = out1['message'][-1].content\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dca9a212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count ->  105\n",
      "ok my self adnan saeed\n",
      "Nice to meet you, Adnan Saeed! It's great to have you here. I hope you're doing well. Is there something specific you'd like to talk about or ask me, or would you like to just chat and see where the conversation goes?\n",
      "\n",
      "By the way, where are you from, Adnan? I'm curious to know more about you and your interests.\n",
      "now tell me about my self\n",
      "I'd love to try. However, since we just started chatting, I don't have much information about you yet. But I can try to make some general and fun observations based on our brief conversation.\n",
      "\n",
      "Here's what I've gathered so far:\n",
      "\n",
      "1. **Your name is Adnan Saeed**: That's a great start! I now know how to address you.\n",
      "2. **You're interested in chatting**: You initiated this conversation, which suggests that you're curious and open to meeting new people or exploring new topics.\n",
      "3. **You might be from a diverse cultural background**: Your name, Adnan Saeed, has roots in various cultures, including Arabic, Urdu, and other languages spoken in the Middle East and South Asia. This could mean that you have a rich cultural heritage and a unique perspective on the world.\n",
      "\n",
      "That's about all I can infer for now. To learn more about you, I'd love to ask some questions:\n",
      "\n",
      "* What do you do for work or study?\n",
      "* What are your hobbies or interests?\n",
      "* Where are you from, and what's your favorite thing about your hometown?\n",
      "* What brings you here today, and what would you like to talk about?\n",
      "\n",
      "Feel free to share as much or as little as you'd like, and I'll do my best to get to know you better!\n"
     ]
    }
   ],
   "source": [
    "out1 = graph.invoke({'message': HumanMessage(content='now tell me about my self')}, config)\n",
    "out1 = out1['message'][-1].content\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d73a984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count ->  8\n",
      "hi how are you?\n",
      "Hello. I'm just a language model, so I don't have emotions or feelings like humans do, but I'm functioning properly and ready to help with any questions or tasks you might have. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "out1 = graph.invoke({'message': HumanMessage(content='hi how are you?')}, config)\n",
    "out1 = out1['message'][-1].content\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bc0eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count ->  73\n",
      "hi how are you?\n",
      "Hello. I'm just a language model, so I don't have emotions or feelings like humans do, but I'm functioning properly and ready to help with any questions or tasks you might have. How can I assist you today?\n",
      "what is my name?\n",
      "I don't know your name. I'm a large language model, I don't have the ability to retain personal information about users, and our conversation just started, so I haven't received any information about you. If you'd like to share your name, I'd be happy to chat with you and use it in our conversation.\n"
     ]
    }
   ],
   "source": [
    "out1 = graph.invoke({'message': HumanMessage(content='what is my name?')}, config)\n",
    "out1 = out1['message'][-1].content\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ebaca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count ->  100\n",
      "what is my name?\n",
      "I don't know your name. I'm a large language model, I don't have the ability to retain personal information about users, and our conversation just started, so I haven't received any information about you. If you'd like to share your name, I'd be happy to chat with you and use it in our conversation.\n",
      "my name is adnan saeed ok\n",
      "Nice to meet you, Adnan Saeed. It's great to have a name to associate with our conversation. How's your day going so far, Adnan? Is there something I can help you with or would you like to chat about a particular topic?\n"
     ]
    }
   ],
   "source": [
    "out1 = graph.invoke({'message': HumanMessage(content='my name is adnan saeed ok')}, config)\n",
    "out1 = out1['message'][-1].content\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf5b6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count ->  83\n",
      "my name is adnan saeed ok\n",
      "Nice to meet you, Adnan Saeed. It's great to have a name to associate with our conversation. How's your day going so far, Adnan? Is there something I can help you with or would you like to chat about a particular topic?\n",
      "write blog should be 50 words\n",
      "\"Hello, I'm Adnan Saeed. Welcome to my blog, where I share thoughts and experiences. Stay tuned for insightful posts on various topics, from tech to lifestyle. Let's connect and explore new ideas together, every week, here on my blog.\"\n"
     ]
    }
   ],
   "source": [
    "out1 = graph.invoke({'message': HumanMessage(content='write blog should be 50 words')}, config)\n",
    "out1 = out1['message'][-1].content\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4020c8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count ->  144\n",
      "Nice to meet you, Adnan Saeed. It's great to have a name to associate with our conversation. How's your day going so far, Adnan? Is there something I can help you with or would you like to chat about a particular topic?\n",
      "write blog should be 50 words\n",
      "\"Hello, I'm Adnan Saeed. Welcome to my blog, where I share thoughts and experiences. Stay tuned for insightful posts on various topics, from tech to lifestyle. Let's connect and explore new ideas together, every week, here on my blog.\"\n",
      "what is my name\n",
      "Your name is Adnan Saeed.\n"
     ]
    }
   ],
   "source": [
    "out1 = graph.invoke({'message': HumanMessage(content='what is my name')}, config)\n",
    "out1 = out1['message'][-1].content\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f46374f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count ->  102\n",
      "write blog should be 50 words\n",
      "\"Hello, I'm Adnan Saeed. Welcome to my blog, where I share thoughts and experiences. Stay tuned for insightful posts on various topics, from tech to lifestyle. Let's connect and explore new ideas together, every week, here on my blog.\"\n",
      "what is my name\n",
      "Your name is Adnan Saeed.\n",
      "again\n",
      "Your name is not specified, I apologize for the earlier assumption. You didn't mention your name in our conversation. If you'd like to share it, I'd be happy to know.\n"
     ]
    }
   ],
   "source": [
    "out1 = graph.invoke({'message': HumanMessage(content='again')}, config)\n",
    "out1 = out1['message'][-1].content\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be9242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
