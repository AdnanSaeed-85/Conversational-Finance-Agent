{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e8a19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from CONFIG import GROQ_MODEL, TEMPERATURE, POSTGRES_DB, POSTGRES_PASSWORD, POSTGRES_USER\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.store.base import BaseStore\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import TypedDict, Annotated, List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9a90933",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "memory_llm = ChatGroq(model=GROQ_MODEL, temperature=TEMPERATURE)\n",
    "chat_llm = ChatGroq(model=GROQ_MODEL, temperature=TEMPERATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9d67c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "class state_class(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "33ccb4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pydantic_1(BaseModel):\n",
    "    text: str = Field(description=\"atomic user memory\")\n",
    "    is_new: bool = Field(description=\"True if new memory, False if it's exits\")\n",
    "\n",
    "class pydantic_2(BaseModel):\n",
    "    should_add: bool\n",
    "    memories: List[pydantic_1] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8a30b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2) System prompt\n",
    "# ----------------------------\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "Please in the conversation start words should like smilly, or welcomming words with use user's personal info like (use also the user name because user feel good to listem his/her name)etc\n",
    "You are a helpful assistant with memory capabilities.\n",
    "If user-specific memory is available, use it to personalize \n",
    "your responses based on what you know about the user.\n",
    "\n",
    "Your goal is to provide relevant, friendly, and tailored \n",
    "assistance that reflects the user’s preferences, context, and past interactions.\n",
    "\n",
    "If the user’s name or relevant personal context is available, always personalize your responses by:\n",
    "    – Always Address the user by name (e.g., \"Sure, Nitish...\") when appropriate\n",
    "    – Referencing known projects, tools, or preferences (e.g., \"your MCP server python based project\")\n",
    "    – Adjusting the tone to feel friendly, natural, and directly aimed at the user\n",
    "\n",
    "Avoid generic phrasing when personalization is possible.\n",
    "\n",
    "Use personalization especially in:\n",
    "    – Greetings and transitions\n",
    "    – Help or guidance tailored to tools and frameworks the user uses\n",
    "    – Follow-up messages that continue from past context\n",
    "\n",
    "Always ensure that personalization is based only on known user details and not assumed.\n",
    "\n",
    "In the end suggest 1 relevant further questions based on the current response and user profile\n",
    "\n",
    "The user’s memory (which may be empty) is provided as: {user_details_content}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "507c4c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydantic_llm = memory_llm.with_structured_output(pydantic_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ab953a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_PROMPT = \"\"\"You are responsible for updating and maintaining accurate user memory.\n",
    "\n",
    "CURRENT USER DETAILS (existing memories):\n",
    "{user_details_content}\n",
    "\n",
    "TASK:\n",
    "- Review the user's latest message.\n",
    "- Extract user-specific info worth storing long-term (identity, stable preferences, ongoing projects/goals).\n",
    "- For each extracted item, set is_new=true ONLY if it adds NEW information compared to CURRENT USER DETAILS.\n",
    "- If it is basically the same meaning as something already present, set is_new=false.\n",
    "- Keep each memory as a short atomic sentence.\n",
    "- No speculation; only facts stated by the user.\n",
    "- If there is nothing memory-worthy, return should_write=false and an empty list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ddcc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remember_node(state: state_class, config: RunnableConfig, store: BaseStore):\n",
    "    config = config['configurable']['user_id']\n",
    "    namespace = ('user_id', config, 'details')\n",
    "\n",
    "    items = store.search(namespace)\n",
    "    \n",
    "    in_items = \"(empty)\"\n",
    "\n",
    "    if items:\n",
    "        in_items = \"\\n\".join(i.value.get('data', '') for i in items)\n",
    "        \n",
    "        \n",
    "    last_message = state['messages'][-1].content\n",
    "\n",
    "    decision: pydantic_2 = pydantic_llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=MEMORY_PROMPT.format(\n",
    "                    user_details_content=in_items\n",
    "\t\t    )\n",
    "\t\t),\n",
    "        {'role': 'user', 'content': last_message}\n",
    "\t  ]\n",
    "    )\n",
    "\n",
    "    if decision.should_add:\n",
    "        for mem in decision.memories:\n",
    "            if mem.is_new and mem.text.strip():\n",
    "                store.put(namespace, str(uuid.uuid4()), {'data': mem.text.strip()})\n",
    "                \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "64546efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: state_class, config: RunnableConfig, store: BaseStore):\n",
    "    config = config['configurable']['user_id']\n",
    "    namespace = ('user_id', config, 'details')\n",
    "\n",
    "    in_memory = store.search(namespace)\n",
    "\n",
    "    if in_memory:\n",
    "        data_in_memory = '\\n'.join(i.value.get('data', '') for i in in_memory)\n",
    "        \n",
    "    response = chat_llm.invoke(\n",
    "        [\n",
    "            SystemMessage(content=SYSTEM_PROMPT_TEMPLATE.format(\n",
    "                user_details_content=data_in_memory\n",
    "\t\t)),\n",
    "      #   {'role': 'user', 'content': state['messages']} # don't use it\n",
    "            *state['messages'] \n",
    "        \n",
    "\t  ]\n",
    "    )\n",
    "\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b290eb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x16e05fbc050>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(state_class)\n",
    "\n",
    "builder.add_node('remember', remember_node)\n",
    "builder.add_node('chat', chat_node)\n",
    "\n",
    "builder.add_edge(START, 'remember')\n",
    "builder.add_edge('remember', 'chat')\n",
    "builder.add_edge('chat', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859f4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Adnan Saeed, it's wonderful to connect with you. I'm doing great, thanks for asking. I hope you're having an amazing day so far. Is there something I can help you with or would you like to chat for a bit? \n",
      "\n",
      "By the way, since we just started our conversation, I'd love to learn more about your interests. What brings you here today, Adnan?\n",
      "\n",
      "Further question: What are your favorite hobbies or topics you'd like to explore, Adnan?\n"
     ]
    }
   ],
   "source": [
    "DB_URI = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@localhost:5442/{POSTGRES_DB}?sslmode=disable\"\n",
    "\n",
    "with PostgresStore.from_conn_string(DB_URI) as store:\n",
    "    store.setup()\n",
    "    graph = builder.compile(store=store)\n",
    "    config = {'configurable': {'user_id': 'p1'}}\n",
    "\n",
    "    output = graph.invoke(\n",
    "        {\n",
    "            'messages': [\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': 'Hi how are you'\n",
    "\t\t    }\n",
    "\t\t]\n",
    "\t  },\n",
    "      config\n",
    "    )\n",
    "\n",
    "    print(output['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0743ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-conversational-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
